# ğŸ§ FURIA Echo

**FURIA Echo** Ã© um web chat interativo onde fÃ£s da FURIA podem conversar com ecos digitais de Ã­dolos do time de CS:GO, como **FalleN**, **Guerri**, **Sidde**, **KSCERATO**, **yuurih** e atÃ© com **"a FURIA"**, uma persona que representa a organizaÃ§Ã£o em si.  
As respostas sÃ£o geradas por uma **IA gratuita** e treinada com **conteÃºdos reais**, como entrevistas, notÃ­cias, estatÃ­sticas e curiosidades sobre o time e seus membros.

---

## ğŸ§  Como funciona

O usuÃ¡rio escolhe com quem quer conversar, e cada personagem responde com base em sua **personalidade real**, **estilo de fala** e **conhecimento especÃ­fico**. A IA Ã© limitada por uma base de dados curada para garantir fidelidade e coerÃªncia nas respostas.

### Personagens disponÃ­veis:
- ğŸ§” **FalleN** â€” o professor tÃ¡tico, responde com profundidade e calma
- ğŸ§¢ **Guerri** â€” o antigo coach, mostrando conhecimento e vivencia na organizaÃ§Ã£o
- ğŸ™ï¸ **Sidde** â€” o coach, focado no time e na preparaÃ§Ã£o
- ğŸ¯ **KSCERATO** â€” o foco no clutch, frio e direto
- ğŸ”¥ **yuurih** â€” agressivo e confiante, sempre com energia
- ğŸ¯ **a FURIA** â€” a organizaÃ§Ã£o em si, responde sobre notÃ­cias, prÃ³ximos jogos e estrutura do time

---

## ğŸ’» Stack utilizada

- **Frontend**: React + TailwindCSS
- **Backend**: Django + Django REST Framework
- **IA**: [LLaMA (LNM)](https://openrouter.ai) via OpenRouter API (modelo gratuito)
- **Hospedagem**: Vercel (frontend) + Railway/Render/Heroku (backend, opcional)
- **Design de referÃªncia**: WeChat no Apple Vision Pro

---

## ğŸ–¼ï¸ ProtÃ³tipo

Interface inspirada no WeChat do Vision Pro, com visual limpo, moderno e imersivo para focar no conteÃºdo das conversas.

![ProtÃ³tipo FURIA Echo](./assets/Furia%20ECHO.png)

---

## ğŸš€ Como rodar localmente

### 1. Backend (Django)

```bash
cd backend
python -m venv venv
source venv/bin/activate  # ou venv\Scripts\activate no Windows
pip install -r requirements.txt

# Crie um .env com sua chave da OpenRouter
touch .env
```

`.env`
```
OPENROUTER_API_KEY=your_openrouter_key_here
```

```bash
python manage.py runserver
```

---

### 2. Frontend (React)

```bash
cd frontend
npm install
npm run dev
```

---

## ğŸ” Fluxo de funcionamento

1. UsuÃ¡rio acessa o chat e escolhe um personagem.
2. Frontend envia a mensagem + personagem escolhido para o backend Django.
3. Django monta o prompt especÃ­fico com base no personagem.
4. Backend envia a solicitaÃ§Ã£o para o modelo **LLaMA (LNM)** via OpenRouter.
5. A resposta Ã© retornada ao frontend para exibiÃ§Ã£o no chat.

---

## ğŸ“‚ Estrutura do projeto

```
furia-echo/
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/     # UI do chat
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â””â”€â”€ services/       # API calls
â”œâ”€â”€ assets/                 # ProtÃ³tipos, imagens, logos
â””â”€â”€ README.md
```

---

## ğŸ’¬ Exemplos de perguntas

- "FalleN, como vocÃª prepara a equipe mentalmente antes de um Major?"
- "Guerri, qual Ã© a principal diferenÃ§a do time de 2020 pro atual?"
- "FURIA, qual Ã© o prÃ³ximo jogo do time?"
- "Sidde, explique como funciona um clutch 1v3 do KSCERATO!"
- "yuurih, como vocÃª mantÃ©m o foco mesmo quando o time estÃ¡ perdendo?"

---

## ğŸ“½ï¸ VÃ­deo demonstrativo

ğŸ¥ Em breve: link para o vÃ­deo com tour completo pela aplicaÃ§Ã£o.

---

## ğŸ“š CrÃ©ditos

- Desenvolvido por: Douglas Marinho Martins
- Dados base: HLTV, Liquipedia, Twitter da FURIA, entrevistas e fontes oficiais
- IA: [OpenRouter](https://openrouter.ai) - Modelo gratuito LLaMA (LNM)

---

## ğŸ“¬ Contato

SugestÃµes ou dÃºvidas?  
Me chama no [LinkedIn](https://www.linkedin.com/in/dodax/) ou abra uma issue aqui no GitHub!
